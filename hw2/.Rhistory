# initialize
phi <- matrix(0.5, nrow = nrow(dilution), ncol = 2) # Cluster responsibilities
nrow(dilution)
dilution
elbo_values <- numeric(iter)
# initialize
phi <- matrix(0.5, nrow = length(dilution), ncol = 2) # Cluster responsibilities
mu <- runif(2, min(dilution), max(dilution)) # Means
sigma_sq <- rep(1, 2)
for (it in 1:iter) {
# E-step: Update variational distribution q(z)
for (i in 1:nrow(dilution)) {
for (k in 1:2) {
log_rho <- log(0.5) + dnorm(dilution[i], mean = mu[k], sd = sqrt(sigma_sq[k]), log = TRUE)
phi[i, k] <- exp(log_rho)
}
phi[i, ] <- phi[i, ] / sum(phi[i, ])
}
# M-step: Update mu, sigma2
for (k in 1:2) {
mu[k] <- sum(phi[, k] * dilution) / sum(phi[, k])
sigma_sq[k] <- sum(phi[, k] * (dilution - mu[k])^2) / sum(phi[, k])
}
# Compute ELBO
elbo <- 0
for (i in 1:nrow(dilution)) {
for (k in 1:2) {
elbo <- elbo + phi[i, k] * (log(0.5) + dnorm(dilution, mean = mu[k], sd = sqrt(sigma_sq[k]), log = TRUE) - log(phi[i, k]))
}
}
elbo_values[it] <- elbo
# Check for convergence
if (it > 1 && abs(elbo_values[it] - elbo_values[it - 1]) < 1e-6) {
break
}
}
elbo_values <- numeric(iter)
# initialize
phi <- matrix(0.5, nrow = length(dilution), ncol = 2) # Cluster responsibilities
mu <- runif(2, min(dilution), max(dilution)) # Means
sigma_sq <- rep(1, 2)
for (it in 1:iter) {
# E-step: Update variational distribution q(z)
for (i in 1:length(dilution)) {
for (k in 1:2) {
log_rho <- log(0.5) + dnorm(dilution[i], mean = mu[k], sd = sqrt(sigma_sq[k]), log = TRUE)
phi[i, k] <- exp(log_rho)
}
phi[i, ] <- phi[i, ] / sum(phi[i, ])
}
# M-step: Update mu, sigma2
for (k in 1:2) {
mu[k] <- sum(phi[, k] * dilution) / sum(phi[, k])
sigma_sq[k] <- sum(phi[, k] * (dilution - mu[k])^2) / sum(phi[, k])
}
# Compute ELBO
elbo <- 0
for (i in 1:nrow(dilution)) {
for (k in 1:2) {
elbo <- elbo + phi[i, k] * (log(0.5) + dnorm(dilution, mean = mu[k], sd = sqrt(sigma_sq[k]), log = TRUE) - log(phi[i, k]))
}
}
elbo_values[it] <- elbo
# Check for convergence
if (it > 1 && abs(elbo_values[it] - elbo_values[it - 1]) < 1e-6) {
break
}
}
elbo_values <- numeric(iter)
# initialize
phi <- matrix(0.5, nrow = length(dilution), ncol = 2) # Cluster responsibilities
mu <- runif(2, min(dilution), max(dilution)) # Means
sigma_sq <- rep(1, 2)
for (it in 1:iter) {
# E-step: Update variational distribution q(z)
for (i in 1:length(dilution)) {
for (k in 1:2) {
log_rho <- log(0.5) + dnorm(dilution[i], mean = mu[k], sd = sqrt(sigma_sq[k]), log = TRUE)
phi[i, k] <- exp(log_rho)
}
phi[i, ] <- phi[i, ] / sum(phi[i, ])
}
# M-step: Update mu, sigma2
for (k in 1:2) {
mu[k] <- sum(phi[, k] * dilution) / sum(phi[, k])
sigma_sq[k] <- sum(phi[, k] * (dilution - mu[k])^2) / sum(phi[, k])
}
# Compute ELBO
elbo <- 0
for (i in 1:length(dilution)) {
for (k in 1:2) {
elbo <- elbo + phi[i, k] * (log(0.5) + dnorm(dilution, mean = mu[k], sd = sqrt(sigma_sq[k]), log = TRUE) - log(phi[i, k]))
}
}
elbo_values[it] <- elbo
# Check for convergence
if (it > 1 && abs(elbo_values[it] - elbo_values[it - 1]) < 1e-6) {
break
}
}
dilution[1]
dnorm(dilution[1])
elbo_values <- numeric(iter)
# initialize
phi <- matrix(0.5, nrow = length(dilution), ncol = 2) # Cluster responsibilities
mu <- runif(2, min(dilution), max(dilution)) # Means
sigma_sq <- rep(1, 2)
for (it in 1:iter) {
# E-step: Update variational distribution q(z)
for (i in 1:length(dilution)) {
for (k in 1:2) {
log_rho <- log(0.5) + dnorm(dilution[i], mean = mu[k], sd = sqrt(sigma_sq[k]), log = TRUE)
phi[i, k] <- exp(log_rho)
}
phi[i, ] <- phi[i, ] / sum(phi[i, ])
}
# M-step: Update mu, sigma2
for (k in 1:2) {
mu[k] <- sum(phi[, k] * dilution) / sum(phi[, k])
sigma_sq[k] <- sum(phi[, k] * (dilution - mu[k])^2) / sum(phi[, k])
}
# Compute ELBO
elbo <- 0
for (i in 1:length(dilution)) {
for (k in 1:2) {
elbo <- elbo + phi[i, k] * (log(0.5) + dnorm(dilution[i], mean = mu[k], sd = sqrt(sigma_sq[k]), log = TRUE) - log(phi[i, k]))
}
}
elbo_values[it] <- elbo
# Check for convergence
if (it > 1 && abs(elbo_values[it] - elbo_values[it - 1]) < 1e-6) {
break
}
}
elbo_values <- numeric(iter)
# initialize
phi <- matrix(0.5, nrow = length(dilution), ncol = 2) # Cluster responsibilities
mu <- runif(2, min(dilution), max(dilution)) # Means
sigma_sq <- rep(1, 2)
for (it in 1:iter) {
# E-step: Update variational distribution q(z)
for (i in 1:length(dilution)) {
for (k in 1:2) {
log_rho <- log(0.5) + dnorm(dilution[i], mean = mu[k], sd = sqrt(sigma_sq[k]), log = TRUE)
phi[i, k] <- exp(log_rho)
}
phi[i, ] <- phi[i, ] / sum(phi[i, ])
}
# M-step: Update mu, sigma2
for (k in 1:2) {
mu[k] <- sum(phi[, k] * dilution) / sum(phi[, k])
sigma_sq[k] <- sum(phi[, k] * (dilution - mu[k])^2) / sum(phi[, k])
}
# Compute ELBO
elbo <- 0
for (i in 1:length(dilution)) {
for (k in 1:2) {
elbo <- elbo + phi[i, k] * (log(0.5) + dnorm(dilution[i], mean = mu[k], sd = sqrt(sigma_sq[k]), log = TRUE) - log(phi[i, k]))
}
}
elbo_values[it] <- elbo
# if (it > 1 && abs(elbo_values[it] - elbo_values[it - 1]) < 1e-6) {
#   break
# }
}
# Plot ELBO
ggplot(data.frame(Iteration = 1:iter, ELBO = elbo_values), aes(x = Iteration, y = ELBO)) +
geom_line() + theme_minimal() + labs(y = "ELBO", x = "Iteration")
iter
iter <- 1000
elbo_values <- numeric(iter)
# initialize
phi <- matrix(0.5, nrow = length(dilution), ncol = 2) # Cluster responsibilities
mu <- runif(2, min(dilution), max(dilution)) # Means
sigma_sq <- rep(1, 2)
for (it in 1:iter) {
# E-step: Update variational distribution q(z)
for (i in 1:length(dilution)) {
for (k in 1:2) {
log_rho <- log(0.5) + dnorm(dilution[i], mean = mu[k], sd = sqrt(sigma_sq[k]), log = TRUE)
phi[i, k] <- exp(log_rho)
}
phi[i, ] <- phi[i, ] / sum(phi[i, ])
}
# M-step: Update mu, sigma2
for (k in 1:2) {
mu[k] <- sum(phi[, k] * dilution) / sum(phi[, k])
sigma_sq[k] <- sum(phi[, k] * (dilution - mu[k])^2) / sum(phi[, k])
}
# Compute ELBO
elbo <- 0
for (i in 1:length(dilution)) {
for (k in 1:2) {
elbo <- elbo + phi[i, k] * (log(0.5) + dnorm(dilution[i], mean = mu[k], sd = sqrt(sigma_sq[k]), log = TRUE) - log(phi[i, k]))
}
}
elbo_values[it] <- elbo
if (it > 1 && abs(elbo_values[it] - elbo_values[it - 1]) < 1e-6) {
break
}
}
iter <- 1000
elbo_values <- numeric(iter)
# initialize
phi <- matrix(0.5, nrow = length(dilution), ncol = 2) # Cluster responsibilities
mu <- runif(2, min(dilution), max(dilution)) # Means
sigma_sq <- rep(1, 2)
for (it in 1:iter) {
# E-step: Update variational distribution q(z)
for (i in 1:length(dilution)) {
for (k in 1:2) {
log_rho <- log(0.5) + dnorm(dilution[i], mean = mu[k], sd = sqrt(sigma_sq[k]), log = TRUE)
phi[i, k] <- exp(log_rho)
}
phi[i, ] <- phi[i, ] / sum(phi[i, ])
}
# M-step: Update mu, sigma2
for (k in 1:2) {
mu[k] <- sum(phi[, k] * dilution) / sum(phi[, k])
sigma_sq[k] <- sum(phi[, k] * (dilution - mu[k])^2) / sum(phi[, k])
}
# Compute ELBO
elbo <- 0
for (i in 1:length(dilution)) {
for (k in 1:2) {
elbo <- elbo + phi[i, k] * (log(0.5) + dnorm(dilution[i], mean = mu[k], sd = sqrt(sigma_sq[k]), log = TRUE) - log(phi[i, k]))
}
}
elbo_values[it] <- elbo
# if (it > 1 && abs(elbo_values[it] - elbo_values[it - 1]) < 1e-6) {
#   break
# }
}
# Plot ELBO
ggplot(data.frame(Iteration = 1:iter, ELBO = elbo_values), aes(x = Iteration, y = ELBO)) +
geom_line() + theme_minimal() + labs(y = "ELBO", x = "Iteration")
# Variational Inference
n_iter <- 1000
elbo_values <- numeric(n_iter)
# Initialize variational parameters
phi <- matrix(0.5, nrow = length(dilution), ncol = 2) # Cluster responsibilities
mu <- runif(2, min(dilution), max(dilution)) # Means
sigma_sq <- rep(1, 2) # Variances
for (iter in 1:n_iter) {
# E-step: Update variational distribution q(z)
for (i in 1:length(dilution)) {
for (k in 1:2) {
log_rho <- log(0.5) + dnorm(dilution[i], mean = mu[k], sd = sqrt(sigma_sq[k]), log = TRUE)
phi[i, k] <- exp(log_rho)
}
phi[i, ] <- phi[i, ] / sum(phi[i, ])
}
# M-step: Update variational parameters mu, sigma_sq
for (k in 1:2) {
mu[k] <- sum(phi[, k] * dilution) / sum(phi[, k])
sigma_sq[k] <- sum(phi[, k] * (dilution - mu[k])^2) / sum(phi[, k])
}
# Compute ELBO
elbo <- 0
for (i in 1:length(dilution)) {
for (k in 1:2) {
elbo <- elbo + phi[i, k] * (log(0.5) + dnorm(dilution[i], mean = mu[k], sd = sqrt(sigma_sq[k]), log = TRUE) - log(phi[i, k]))
}
}
elbo_values[iter] <- elbo
# Check for convergence
if (iter > 1 && abs(elbo_values[iter] - elbo_values[iter - 1]) < 1e-6) {
break
}
}
library(tibble)
library(dplyr)
library(ggplot2)
# Define the data
dilution_standards_data <- tibble::tribble(
~conc, ~dilution, ~y,
2000, 1, c(2.341, 2.47),
667, 1 / 2, c(2.308, 2.243),
222, 1 / 4, c(1.95, 1.955),
74.1, 1 / 8, c(0.975, 0.961),
25, 1 / 16, c(0.302, 0.307),
8.23, 1 / 32, c(0.111, 0.112),
2.74, 1 / 64, c(0.068, 0.07),
0, 0, c(0.058, 0.062),
) %>%
mutate(rep = purrr::map(conc, ~ c("a", "b"))) %>%
unnest(c(y, rep))
# Variational Inference
n_iter <- 1000
elbo_values <- numeric(n_iter)
# Initialize variational parameters
phi <- matrix(0.5, nrow = nrow(dilution_standards_data), ncol = 2) # Cluster responsibilities
mu <- runif(2, min(dilution_standards_data$y), max(dilution_standards_data$y)) # Means
sigma_sq <- rep(1, 2) # Variances
for (iter in 1:n_iter) {
# E-step: Update variational distribution q(z)
for (i in 1:nrow(dilution_standards_data)) {
for (k in 1:2) {
log_rho <- log(0.5) + dnorm(dilution_standards_data$y[i], mean = mu[k], sd = sqrt(sigma_sq[k]), log = TRUE)
phi[i, k] <- exp(log_rho)
}
phi[i, ] <- phi[i, ] / sum(phi[i, ])
}
# M-step: Update variational parameters mu, sigma_sq
for (k in 1:2) {
mu[k] <- sum(phi[, k] * dilution_standards_data$y) / sum(phi[, k])
sigma_sq[k] <- sum(phi[, k] * (dilution_standards_data$y - mu[k])^2) / sum(phi[, k])
}
# Compute ELBO
elbo <- 0
for (i in 1:nrow(dilution_standards_data)) {
for (k in 1:2) {
elbo <- elbo + phi[i, k] * (log(0.5) + dnorm(dilution_standards_data$y[i], mean = mu[k], sd = sqrt(sigma_sq[k]), log = TRUE) - log(phi[i, k]))
}
}
elbo_values[iter] <- elbo
# Check for convergence
if (iter > 1 && abs(elbo_values[iter] - elbo_values[iter - 1]) < 1e-6) {
break
}
}
# Plot ELBO
ggplot(data.frame(Iteration = 1:n_iter, ELBO = elbo_values), aes(x = Iteration, y = ELBO)) +
geom_line() +
theme_minimal() +
labs(title = "Convergence of Variational Inference", y = "ELBO", x = "Iteration")
# You can perform further model checking by comparing predictions on held-out data
# # read csv
# dilution <- read.csv("reconstructed.csv", header = FALSE)
# # store in a long vector
# dilution <- as.vector(t(dilution))
# hist(dilution, breaks = 30)
# # use ggplot to hist
# ggplot(data.frame(dilution), aes(x = dilution)) +
#   geom_histogram(binwidth = 0.125, color = "black", fill = "light blue") +
#   theme_minimal() +
#   labs(title = "Histogram of signal response", y = "Frequency", x = "Signal response")
print(elbo)
elbo_values
# Variational Inference
n_iter <- 1000
elbo_values <- numeric(n_iter)
elbo_values
phi
mu
sigma_sq
# Initialize variational parameters
phi <- matrix(0.5, nrow = length(dilution), ncol = 2) # Cluster responsibilities
mu <- runif(2, min(dilution), max(dilution)) # Means
sigma_sq <- rep(1, 2) # Variances
mu
sigma_sq
dilution_standards_data$y
dilution
n_iter <- 1000
elbo_values <- numeric(n_iter)
# Initialize variational parameters
phi <- matrix(0.5, nrow = length(dilution), ncol = 2)
mu <- runif(2, min(dilution), max(dilution))
sigma_sq <- rep(1, 2)
for (iter in 1:n_iter) {
# E-step: Update variational distribution q(z)
for (i in 1:length(dilution)) {
for (k in 1:2) {
log_rho <- log(0.5) + dnorm(dilution[i], mean = mu[k], sd = sqrt(sigma_sq[k]), log = TRUE)
phi[i, k] <- exp(log_rho)
}
phi[i, ] <- phi[i, ] / sum(phi[i, ])
if(any(is.na(phi[i, ]))) {
stop("NA values in phi during iteration ", iter)
}
}
# M-step: Update variational parameters mu, sigma_sq
for (k in 1:2) {
mu[k] <- sum(phi[, k] * dilution) / sum(phi[, k])
sigma_sq[k] <- sum(phi[, k] * (dilution - mu[k])^2) / sum(phi[, k])
if(is.na(mu[k]) || is.na(sigma_sq[k])) {
stop("NA values in mu or sigma_sq during iteration ", iter)
}
}
# Compute ELBO
elbo <- 0
for (i in 1:length(dilution)) {
for (k in 1:2) {
elbo <- elbo + phi[i, k] * (log(0.5) + dnorm(dilution[i], mean = mu[k], sd = sqrt(sigma_sq[k]), log = TRUE) - log(phi[i, k]))
}
}
elbo_values[iter] <- elbo
if(is.na(elbo)) {
stop("NA value in ELBO during iteration ", iter)
}
# Check for convergence
if (iter > 1 && abs(elbo_values[iter] - elbo_values[iter - 1]) < 1e-6) {
break
}
}
dilution_standards_data$y <- dilution
# Variational Inference
n_iter <- 1000
elbo_values <- numeric(n_iter)
# Initialize variational parameters
phi <- matrix(0.5, nrow = length(dilution), ncol = 2) # Cluster responsibilities
mu <- runif(2, min(dilution), max(dilution)) # Means
sigma_sq <- rep(1, 2) # Variances
for (iter in 1:n_iter) {
# E-step: Update variational distribution q(z)
for (i in 1:length(dilution)) {
for (k in 1:2) {
log_rho <- log(0.5) + dnorm(dilution[i], mean = mu[k], sd = sqrt(sigma_sq[k]), log = TRUE)
phi[i, k] <- exp(log_rho)
}
phi[i, ] <- phi[i, ] / sum(phi[i, ])
}
# M-step: Update variational parameters mu, sigma_sq
for (k in 1:2) {
mu[k] <- sum(phi[, k] * dilution) / sum(phi[, k])
sigma_sq[k] <- sum(phi[, k] * (dilution - mu[k])^2) / sum(phi[, k])
}
# Compute ELBO
elbo <- 0
for (i in 1:length(dilution)) {
for (k in 1:2) {
elbo <- elbo + phi[i, k] * (log(0.5) + dnorm(dilution[i], mean = mu[k], sd = sqrt(sigma_sq[k]), log = TRUE) - log(phi[i, k]))
}
}
elbo_values[iter] <- elbo
# # Check for convergence
# if (iter > 1 && abs(elbo_values[iter] - elbo_values[iter - 1]) < 1e-6) {
#   break
# }
}
# Plot ELBO
ggplot(data.frame(Iteration = 1:n_iter, ELBO = elbo_values), aes(x = Iteration, y = ELBO)) +
geom_line() +
theme_minimal() +
labs(title = "Convergence of Variational Inference", y = "ELBO", x = "Iteration")
elbo_values
mu
n_iter <- 1000
elbo_values <- numeric(n_iter)
# Initialize variational parameters
phi <- matrix(0.5, nrow = length(dilution), ncol = 2) # Cluster responsibilities
mu <- runif(2, min(dilution), max(dilution)) # Means
sigma_sq <- rep(1, 2) # Variances
epsilon <- 1e-10  # A small constant to avoid numerical instability
for (iter in 1:n_iter) {
# E-step: Update variational distribution q(z)
for (i in 1:length(dilution)) {
for (k in 1:2) {
log_rho <- log(0.5) + dnorm(dilution[i], mean = mu[k], sd = sqrt(sigma_sq[k] + epsilon), log = TRUE)
phi[i, k] <- exp(log_rho)
}
phi[i, ] <- phi[i, ] / (sum(phi[i, ]) + epsilon)
}
# M-step: Update variational parameters mu, sigma_sq
for (k in 1:2) {
mu[k] <- sum(phi[, k] * dilution) / (sum(phi[, k]) + epsilon)
sigma_sq[k] <- sum(phi[, k] * (dilution - mu[k])^2) / (sum(phi[, k]) + epsilon)
}
# Compute ELBO
elbo <- 0
for (i in 1:length(dilution)) {
for (k in 1:2) {
elbo <- elbo + phi[i, k] * (log(0.5) + dnorm(dilution[i], mean = mu[k], sd = sqrt(sigma_sq[k] + epsilon), log = TRUE) - log(phi[i, k] + epsilon))
}
}
elbo_values[iter] <- elbo
# Optionally, you can add a convergence check here
}
# You can plot ELBO values or return results as needed
elbo_values
ggplot(data.frame(Iteration = 1:n_iter, ELBO = elbo_values), aes(x = Iteration, y = ELBO)) +
geom_line() +
theme_minimal() +
labs(title = "Convergence of Variational Inference", y = "ELBO", x = "Iteration")
elbo_values <- numeric(iter)
# Initialize
phi <- matrix(0.5, nrow = length(dilution), ncol = 2)
mu <- runif(2, min(dilution), max(dilution))
sigma_sq <- rep(1, 2)
epsilon <- 1e-10
for (it in 1:iter) {
# E-step: Update variational distribution q(z)
for (i in 1:length(dilution)) {
for (k in 1:2) {
log_rho <- log(0.5) + dnorm(dilution[i], mean = mu[k], sd = sqrt(sigma_sq[k] + epsilon), log = TRUE)
phi[i, k] <- exp(log_rho)
}
phi[i, ] <- phi[i, ] / (sum(phi[i, ]) + epsilon)
}
# M-step: Update variational parameters mu, sigma_sq
for (k in 1:2) {
mu[k] <- sum(phi[, k] * dilution) / (sum(phi[, k]) + epsilon)
sigma_sq[k] <- sum(phi[, k] * (dilution - mu[k])^2) / (sum(phi[, k]) + epsilon)
}
# Compute ELBO
elbo <- 0
for (i in 1:length(dilution)) {
for (k in 1:2) {
elbo <- elbo + phi[i, k] * (log(0.5) + dnorm(dilution[i], mean = mu[k], sd = sqrt(sigma_sq[k] + epsilon), log = TRUE) - log(phi[i, k] + epsilon))
}
}
elbo_values[it] <- elbo}
# Plot ELBO
ggplot(data.frame(Iteration = 1:iter, ELBO = elbo_values), aes(x = Iteration, y = ELBO)) +
geom_line() +
theme_minimal() +
labs(y = "ELBO", x = "Iteration")
ggplot(data.frame(Iteration = 1:iter, ELBO = elbo_values), aes(x = Iteration, y = ELBO)) +
geom_line() +
theme_minimal() +
labs(y = "ELBO", x = "Iteration")
