{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 11:43:28.845568: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/gpflow/experimental/utils.py:43: UserWarning: You're calling gpflow.experimental.check_shapes.decorator.check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  f\"You're calling {name} which is considered *experimental*.\"\n",
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/gpflow/experimental/utils.py:43: UserWarning: You're calling gpflow.experimental.check_shapes.inheritance.inherit_check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  f\"You're calling {name} which is considered *experimental*.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0. Expected: 2.7.0\n",
      "TensorFlow Probability version: 0.18.0. Expected: 0.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 11:43:51.507280: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from wrapper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAYcMR698j6J"
   },
   "source": [
    "# Experiment II: 2D Spatial Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHthi3uPKLkr"
   },
   "source": [
    "### Model Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "KDl4Di8lKIgm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMA model config: {'lengthscale': 0.07, 'l2_regularizer': 0.15, 'hidden_units': 1024, 'y_noise_std': 0.01, 'activation': None} \n",
      " BNE model config: {'estimate_mean': True, 'estimate_variance': False, 'estimate_skewness': False, 'variance_prior_mean': 0.0, 'skewness_prior_mean': 0.0, 'lengthscale': 4, 'l2_regularizer': 5, 'hidden_units': 1024, 'y_noise_std': 0.1} \n",
      " MAP config: {'learning_rate': 0.0005, 'num_steps': 10000} \n",
      " MCMC config: {'step_size': 0.0001, 'num_steps': 1000, 'burnin': 100, 'nchain': 10, 'seed': 0, 'debug_mode': False}\n"
     ]
    }
   ],
   "source": [
    "# BMA parameters.\n",
    "y_noise_std = 0.01  # Note: Changed from 0.1 # @param\n",
    "bma_gp_lengthscale = .07 # @param\n",
    "bma_gp_l2_regularizer = 0.15 # @param\n",
    "\n",
    "bma_n_samples_train = 100 # @param\n",
    "bma_n_samples_eval = 250 # @param\n",
    "bma_n_samples_test = 250 # @param\n",
    "bma_seed = 0 # @param\n",
    "\n",
    "# Optimization configs. \n",
    "# Consider reduce below parameters / set to `False` if MCMC is taking too long:\n",
    "# mcmc_num_steps, mcmc_burnin, mcmc_nchain, mcmc_initialize_from_map.\n",
    "map_step_size=5e-4   # @param\n",
    "map_num_steps=10_000  # @param\n",
    "\n",
    "mcmc_step_size=1e-4 # @param\n",
    "mcmc_num_steps=1000 # @param\n",
    "\n",
    "mcmc_nchain=10 # @param\n",
    "mcmc_burnin=100 # @param\n",
    "bne_mcmc_initialize_from_map=\"True\" # @param [\"False\", \"True\"]\n",
    "\n",
    "bne_mcmc_initialize_from_map = eval(bne_mcmc_initialize_from_map)\n",
    "\n",
    "      # Assemble into configs.\n",
    "bma_model_config = DEFAULT_GP_CONFIG.copy()\n",
    "map_config = DEFAULT_MAP_CONFIG.copy()\n",
    "mcmc_config = DEFAULT_MCMC_CONFIG.copy()\n",
    "\n",
    "bma_model_config.update(dict(lengthscale=bma_gp_lengthscale,\n",
    "                             l2_regularizer=bma_gp_l2_regularizer,\n",
    "                             y_noise_std=y_noise_std,\n",
    "                             activation=None))\n",
    "\n",
    "map_config.update(dict(learning_rate=map_step_size,\n",
    "                       num_steps=map_num_steps))\n",
    "\n",
    "mcmc_config.update(dict(step_size=mcmc_step_size, \n",
    "                        num_steps=mcmc_num_steps,\n",
    "                       burnin=mcmc_burnin,\n",
    "                       nchain=mcmc_nchain,\n",
    "                       debug_mode=False))\n",
    "\n",
    "# BNE parameters.\n",
    "bne_gp_lengthscale = 4 # 5. # @param\n",
    "bne_gp_l2_regularizer = 5 # 15 # @param\n",
    "bne_variance_prior_mean = -2.5 # @param\n",
    "bne_skewness_prior_mean = -2.5 # @param\n",
    "bne_seed = 0 # @param\n",
    "\n",
    "estimate_mean = \"True\" # @param [\"True\", \"False\"]\n",
    "variance_prior_mean=0. # @param\n",
    "# MAP and MCMC configs\n",
    "\n",
    "bne_gp_config = DEFAULT_GP_CONFIG.copy()\n",
    "bne_model_config = DEFAULT_BNE_CONFIG.copy()\n",
    "\n",
    "\n",
    "\n",
    "bne_gp_config.update(dict(lengthscale=bne_gp_lengthscale, \n",
    "                          l2_regularizer=bne_gp_l2_regularizer))\n",
    "bne_model_config.update(dict(estimate_mean=eval(estimate_mean),\n",
    "                             variance_prior_mean=variance_prior_mean,\n",
    "                             **bne_gp_config))\n",
    "print(\"BMA model config:\", bma_model_config, \"\\n\", \"BNE model config:\", bne_model_config, \"\\n\", \"MAP config:\", map_config, \"\\n\", \"MCMC config:\", mcmc_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training/prediction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(55, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(84421, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred longitude max and min -69.93 -73.5\n",
      "pred latitude max and min 44.3 40.6\n",
      "train longitude max and min -70.023598 -73.443056\n",
      "train latitude max and min 44.107524 40.74529\n"
     ]
    }
   ],
   "source": [
    "training_eastMA = pd.read_csv('../data/training_dataset/training_eastMA.csv')\n",
    "training_eastMA_noMI = training_eastMA[:51]\n",
    "training_eastMA_folds = pd.read_csv('../data/training_dataset/training_eastMA_folds.csv')\n",
    "base_model_predictions_eastMA = pd.read_csv('../data/prediction_dataset/base_model_predictions_eastMA.csv')\n",
    "display(training_eastMA.shape, training_eastMA_folds.shape, base_model_predictions_eastMA.shape)\n",
    "print(\"pred longitude max and min\", base_model_predictions_eastMA[\"lon\"].max(),base_model_predictions_eastMA[\"lon\"].min())\n",
    "print(\"pred latitude max and min\", base_model_predictions_eastMA[\"lat\"].max(),base_model_predictions_eastMA[\"lat\"].min())\n",
    "#list(base_model_predictions_eastMA.columns)\n",
    "print(\"train longitude max and min\", training_eastMA[\"lon\"].max(),training_eastMA[\"lon\"].min())\n",
    "print(\"train latitude max and min\", training_eastMA[\"lat\"].max(),training_eastMA[\"lat\"].min())\n",
    "\n",
    "\n",
    "training51= pd.read_csv('../data/training_dataset/training51.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011 center and scale:  [-72.185104  42.680347] [3.5699997 3.7000008]\n"
     ]
    }
   ],
   "source": [
    "# standardize\n",
    "X_train1 = np.asarray(training_eastMA_noMI[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "X_test1 = np.asarray(base_model_predictions_eastMA[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "X_valid = np.concatenate((X_train1, X_test1), axis=0)\n",
    "X_centr = np.mean(X_valid, axis=0)\n",
    "X_scale = np.max(X_valid, axis=0) - np.min(X_valid, axis=0)\n",
    "\n",
    "X_train1 = (X_train1 - X_centr) / X_scale\n",
    "X_test1 = (X_test1 - X_centr) / X_scale\n",
    "\n",
    "Y_train = np.expand_dims(training_eastMA_noMI[\"aqs\"], 1).astype(np.float32)\n",
    "#Y_test = np.expand_dims(base_model_predictions_eastMA[\"pred_av\"], 1).astype(np.float32)\n",
    "\n",
    "print(\"2011 center and scale: \", X_centr, X_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([51, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([84421, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_names = [\"pred_av\", \"pred_gs\", \"pred_caces\"]\n",
    "base_preds_train = tf.stack([training_eastMA_noMI[base_model_name].astype(np.float32) for base_model_name in base_model_names], axis=-1)\n",
    "base_preds_test = tf.stack([base_model_predictions_eastMA[base_model_name].astype(np.float32) for base_model_name in base_model_names], axis=-1)\n",
    "#base_preds_test\n",
    "display(base_preds_train.shape, base_preds_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.139447 ]\n",
      " [9.068364 ]\n",
      " [4.094172 ]\n",
      " [4.7187085]\n",
      " [8.7675   ]] [[ 8.835652 ]\n",
      " [ 9.485    ]\n",
      " [ 1.58     ]\n",
      " [ 3.8864079]\n",
      " [10.387156 ]]\n",
      "RMSE: 1.4073341\n"
     ]
    }
   ],
   "source": [
    "ref_model.fit(base_preds_tr, Y_tr)\n",
    "Y_pred = ref_model.predict(base_preds_te)\n",
    "# se = np.sqrt(np.mean((Y_pred.reshape(-1,1) - Y_te)**2))\n",
    "# coverage_lr += np.mean((Y_te > Y_pred - 1.96 * se) & (Y_te < Y_pred + 1.96 * se))\n",
    "print(Y_pred, Y_te)\n",
    "print(\"RMSE:\", np.sqrt(np.mean((Y_pred.reshape(-1,1) - Y_te)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "#from rpy2.robjects import pandas2ri\n",
    "from rpy2 import robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "import pandas as pd\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri, r\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "# import R's \"base\" package\n",
    "base = importr('base')\n",
    "#ms = importr('MSGARCH')\n",
    "# import R's \"utils\" package\n",
    "utils = importr('utils')\n",
    "\n",
    "\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "  r_from_pd_df = ro.conversion.py2rpy(training_eastMA_noMI)\n",
    "\n",
    "r_from_pd_df\n",
    "\n",
    "mgcv  = importr('mgcv')\n",
    "stats = importr('stats')\n",
    "ciTools = importr('ciTools')\n",
    "ref_model = LinearRegression()\n",
    "kf = KFold(n_splits=51, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-70.023598 -73.443056 43.629605 40.74529\n",
      "                                     mon_id       aqs  pred_av   pred_gs  \\\n",
      "44             Vermont-Windham-9000-88502-1  1.580000      4.2  8.406383   \n",
      "47          Vermont-Bennington-8001-88502-1  3.886408      4.1  8.559377   \n",
      "40  New Hampshire-Hillsborough-5001-88101-1  4.919658      4.7  8.031440   \n",
      "28     Massachusetts-Hampshire-4002-88502-1  5.086555      6.9  9.584413   \n",
      "20    Massachusetts-Barnstable-0002-88502-1  5.460345      4.6  8.377447   \n",
      "\n",
      "    pred_caces        lon        lat  \n",
      "44    5.113718 -72.909800  42.956100  \n",
      "47    5.990102 -73.126323  43.148176  \n",
      "40    5.744790 -71.878626  42.861830  \n",
      "28    6.099032 -72.334079  42.298493  \n",
      "20    6.027947 -70.023598  41.975804  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.028017044, 0.18252516, 0.038217545, 0.12352848, 0.5268564]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=51, shuffle=True, random_state=0)\n",
    "print(np.max(training_eastMA_noMI[\"lon\"]), np.min(training_eastMA_noMI[\"lon\"]), np.max(training_eastMA_noMI[\"lat\"]), np.min(training_eastMA_noMI[\"lat\"]))\n",
    "# print the 3 smallest elements\n",
    "print(training_eastMA_noMI.nsmallest(5, 'aqs'))\n",
    "# for train_index, test_index in kf.split(X_train1):\n",
    "#       print(\"Train:\", train_index, \"Validation:\",test_index)\n",
    "training_eastMA_noMI.iloc[44]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/keras/initializers/initializers_v2.py:121: UserWarning: The initializer OrthogonalRandomFeatures is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  f\"The initializer {self.__class__.__name__} is unseeded \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MAP:\t399834.0...144029.421875...128314.578125...123061.2421875...120959.84375...119966.65625...119431.1796875...119109.7890625...118900.109375...118754.0078125...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9952358603477478\n",
      "Coverage BMA:  0\n",
      "[0.028017044]\n",
      "Running MAP:\t420005.5625...146330.75...130474.734375...126021.09375...123701.6328125...122609.0390625...121977.84375...121232.25...120988.59375...120850.3984375...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9951955080032349\n",
      "Coverage BMA:  0\n",
      "[0.028017044, 0.18252516]\n",
      "Running MAP:\t404998.53125...143552.5625...132142.65625...126135.96875...123578.09375...122494.3125...121883.9296875...121488.7265625...121219.921875...121030.9375...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9956863522529602\n",
      "Coverage BMA:  0\n",
      "[0.028017044, 0.18252516, 0.038217545]\n",
      "Running MAP:\t400394.40625...149335.640625...134219.09375...128486.59375...125421.5390625...122459.8359375...121283.4609375...120620.140625...120200.609375...119902.640625...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.995209276676178\n",
      "Coverage BMA:  0\n",
      "[0.028017044, 0.18252516, 0.038217545, 0.12352848]\n",
      "Running MAP:\t412482.4375...151359.8125...140475.375...137362.25...134370.171875...133237.671875...132692.21875...132339.71875...131875.84375...131258.28125...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9953711032867432\n",
      "Coverage BMA:  0\n",
      "[0.028017044, 0.18252516, 0.038217545, 0.12352848, 0.5268564]\n",
      "Running MAP:\t382587.625...135553.578125...123772.578125...119628.90625...118047.1640625...117199.421875...116664.6953125...116304.8671875...116054.921875...115876.15625...Done.\n",
      "Running MCMC:\t"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/19/s4zdyd_16mb8h239mgwds83m0000gn/T/ipykernel_25485/980430166.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m                                            \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                                            \u001b[0mmap_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                                            mcmc_config=mcmc_config)\n\u001b[0m\u001b[1;32m     67\u001b[0m       bma_joint_samples = make_bma_samples(X_te, None, base_preds_te, \n\u001b[1;32m     68\u001b[0m                                      \u001b[0mbma_weight_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbma_gp_w_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/BNE_application/Tuning/wrapper_functions.py\u001b[0m in \u001b[0;36mrun_posterior_inference\u001b[0;34m(model_dist, Y, mcmc_config, map_config, model_config, initialize_from_map)\u001b[0m\n\u001b[1;32m    284\u001b[0m   gp_w_samples, _ = run_mcmc(init_state=init_state,\n\u001b[1;32m    285\u001b[0m                              \u001b[0mtarget_log_prob_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_log_prob_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m                              **mcmc_config)  \n\u001b[0m\u001b[1;32m    287\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgp_w_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/BNE_application/Tuning/wrapper_functions.py\u001b[0m in \u001b[0;36mrun_mcmc\u001b[0;34m(init_state, target_log_prob_fn, model_dist, y, sample_size, nchain, num_steps, burnin, step_size, seed, debug_mode, **mcmc_kwargs)\u001b[0m\n\u001b[1;32m   1362\u001b[0m       \u001b[0mburnin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mburnin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m       **mcmc_kwargs)\n\u001b[0m\u001b[1;32m   1365\u001b[0m   \u001b[0;31m# Clear tf.function cache.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2496\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2497\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2499\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1861\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1863\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rmse_lr = []\n",
    "rmse_bma = []\n",
    "rmse_gam = []\n",
    "\n",
    "coverage_lr = 0\n",
    "coverage_gam = 0\n",
    "coverage_bma = 0\n",
    "\n",
    "for train_index, test_index in kf.split(X_train1):\n",
    "      #print(\"Train:\", train_index, \"Validation:\",test_index)\n",
    "      X_tr, X_te = X_train1[train_index], X_train1[test_index] \n",
    "      Y_tr, Y_te = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "      base_preds_tr, base_preds_te = base_preds_train.numpy()[train_index], base_preds_train.numpy()[test_index]\n",
    "      \n",
    "      # Ref: linear regression\n",
    "      # ref_model.fit(X_tr, Y_tr)\n",
    "      # Y_pred = ref_model.predict(X_te)\n",
    "      # se = np.sqrt(np.mean((Y_pred.reshape(-1,1) - Y_te)**2))\n",
    "      # coverage_lr += np.mean((Y_te > Y_pred - 1.96 * se) & (Y_te < Y_pred + 1.96 * se))\n",
    "      \n",
    "      # rmse_lr.append(rmse(Y_te, Y_pred))\n",
    "\n",
    "      r_dat_py = training_eastMA_noMI\n",
    "      #r_dat_py[['lon', 'lat']] = X_train1\n",
    "      \n",
    "      with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "            r_tr = ro.conversion.py2rpy(r_dat_py.iloc[train_index])\n",
    "            r_te = ro.conversion.py2rpy(r_dat_py.iloc[test_index])\n",
    "\n",
    "      # Ref: lr\n",
    "      lr_model = stats.lm(ro.Formula('aqs~pred_av+pred_gs+pred_caces'), data=r_tr)\n",
    "      #l = stats.predict(lr_model, newdata =r_te, interval = 'prediction')\n",
    "      #py_l = np.asanyarray(l).reshape(-1, 3)\n",
    "      #py_l = pd.DataFrame(py_l, columns=['pred', 'l', 'u'])\n",
    "      #lr_ci_l, lr_ci_u = py_l['l'], py_l['u']\n",
    "      l = ciTools.add_pi(r_te, lr_model)\n",
    "      lr_pred = l[7]\n",
    "      lr_ci_l, lr_ci_u = l[8], l[9]\n",
    "      coverage_lr += np.sum([(Y_te[i] > lr_ci_l[i]) & (Y_te[i] < lr_ci_u[i]) for i in range(len(Y_te))])\n",
    "      rmse_lr.append(rmse(Y_te, np.asanyarray(lr_pred).reshape(-1,1)))\n",
    "\n",
    "      # Ref: GAM\n",
    "      #df = training_eastMA_noMI.iloc[train_index]\n",
    "      gam_model = mgcv.gam(ro.Formula('aqs ~ s(lon, lat, by=pred_av, k=4) + s(lon, lat,by=pred_gs, k=4) +s(lon, lat, by=pred_caces, k=4)'), data=r_tr)\n",
    "      a= ciTools.add_pi(r_te, gam_model)\n",
    "      Y_pred = a[7]\n",
    "      gam_ci_l, gam_ci_u = a[8], a[9]\n",
    "      coverage_gam += np.sum([(Y_te[i] > gam_ci_l[i]) & (Y_te[i] < gam_ci_u[i]) for i in range(len(Y_te))])\n",
    "      rmse_gam.append(rmse(Y_te, np.asanyarray(Y_pred).reshape(-1,1)))\n",
    "      #print(rmse_gam)\n",
    "\n",
    "\n",
    "      #BMA\n",
    "      bma_prior, bma_gp_config = bma_dist(X_tr, \n",
    "                                    base_preds_tr, \n",
    "                                    **bma_model_config)\n",
    "\n",
    "      bma_model_config.update(bma_gp_config)\n",
    "\n",
    "\n",
    "      bma_gp_w_samples = run_posterior_inference(model_dist=bma_prior, \n",
    "                                           model_config=bma_model_config,\n",
    "                                           Y=Y_tr, \n",
    "                                           map_config=map_config,\n",
    "                                           mcmc_config=mcmc_config)\n",
    "      bma_joint_samples = make_bma_samples(X_te, None, base_preds_te, \n",
    "                                     bma_weight_samples=bma_gp_w_samples[0],\n",
    "                                     bma_model_config=bma_model_config,\n",
    "                                     n_samples=bma_n_samples_eval, \n",
    "                                     seed=bne_seed,\n",
    "                                     y_samples_only=False)\n",
    "      y_pred = bma_joint_samples['y']\n",
    "      # compute predictive interval\n",
    "      y_pred_mean = np.mean(y_pred, axis=0)\n",
    "      y_pred_std = np.std(y_pred, axis=0)\n",
    "      y_pred_ci = np.stack([y_pred_mean - 1.96 * y_pred_std, y_pred_mean + 1.96 * y_pred_std], axis=1)\n",
    "      # compute coverage\n",
    "      coverage_bma += np.sum([(Y_te[i] > y_pred_ci[i,0]) & (Y_te[i] < y_pred_ci[i,1]) for i in range(len(Y_te))])\n",
    "      print(\"Coverage BMA: \", coverage_bma)\n",
    "\n",
    "      y_pred = tf.reduce_mean(y_pred, axis=0)\n",
    "\n",
    "      rmse_bma.append(rmse(Y_te, y_pred))\n",
    "      print(rmse_bma)      \n",
    "\n",
    "      \n",
    "\n",
    "#print(rmse_lr, rmse_gam)\n",
    "print(\"RMSE LR: \", np.mean(rmse_lr), np.std(rmse_lr))\n",
    "print(\"RMSE GAM: \", np.mean(rmse_gam), np.std(rmse_gam))\n",
    "print(\"Coverage LR: \", coverage_lr, \"Coverage GAM\", coverage_gam)\n",
    "print(coverage_lr/51, coverage_gam/51, coverage_bma/51)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[10.478261],\n",
       "        [10.526711]]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = bma_joint_samples['y']\n",
    "# compute predictive interval\n",
    "y_pred_mean = np.mean(y_pred, axis=0)\n",
    "y_pred_std = np.std(y_pred, axis=0)\n",
    "y_pred_ci = np.stack([y_pred_mean - 1.96 * y_pred_std, y_pred_mean + 1.96 * y_pred_std], axis=1)\n",
    "y_pred_ci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Model Averaging\n",
    "\n",
    "A Bayesian ensemble model where ensemble weights $w_k's$ are parameterized by Gaussian process priors:\n",
    "\n",
    "$y \\sim N(\\mu(x), \\sigma^2)$ \n",
    "\n",
    "$\\mu(x) = \\sum_{k=1}^K w_k(x) * m_k(x) \\quad$  where $\\{m_k\\}_{k=1}^K$ are base model predictions.\n",
    "\n",
    "$w(x) = softmax(f(x)) \\qquad\\;\\;\\;$ where $w=[w_1, \\dots, w_K]$ and $f=[f_1, \\dots, f_K]$\n",
    "\n",
    "$f \\stackrel{i.i.d.}{\\sim} GaussianProcess(0, k)$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check 10-fold Random Cross Validation RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the index of max and min  for lon and lat\n",
    "min_index_lon = training_eastMA_noMI[['lon']].idxmin().values.tolist()\n",
    "max_index_lon = training_eastMA_noMI[['lon']].idxmax().values.tolist()\n",
    "min_index_lat = training_eastMA_noMI[['lat']].idxmin().values.tolist()\n",
    "max_index_lat = training_eastMA_noMI[['lat']].idxmax().values.tolist()\n",
    "# concetenate the index\n",
    "edge_list = min_index_lon + max_index_lon + min_index_lat + max_index_lat\n",
    "# exclude edge_list index from X_train1\n",
    "train_wo_edge = X_train1[~np.isin(np.arange(len(X_train1)), edge_list)]\n",
    "# exclude edge_list index from Y_train\n",
    "Y_wo_edge = Y_train[~np.isin(np.arange(len(Y_train)), edge_list)]\n",
    "# edge_list index from X_train1\n",
    "edge_list_X = X_train1[np.isin(np.arange(len(X_train1)), edge_list)]\n",
    "# edge_list index from Y_train\n",
    "edge_list_Y = Y_train[np.isin(np.arange(len(Y_train)), edge_list)]\n",
    "edge_list_base = base_preds_train[np.isin(np.arange(len(base_preds_train)), edge_list)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_model = LinearRegression()\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "rmse_lr = []\n",
    "rmse_bma = []\n",
    "rmse_gam = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train1):\n",
    "      #print(\"Train:\", train_index, \"Validation:\",test_index)\n",
    "      X_tr, X_te = X_train1[train_index], X_train1[test_index] \n",
    "      Y_tr, Y_te = Y_train[train_index], Y_train[test_index]\n",
    "      \n",
    "      # Ref: linear regression\n",
    "      ref_model.fit(X_tr, Y_tr)\n",
    "      Y_pred = ref_model.predict(X_te)\n",
    "      rmse_lr.append(rmse(Y_te, Y_pred))\n",
    "      print(rmse_lr)\n",
    "\n",
    "\n",
    "      base_preds_tr, base_preds_te = base_preds_train.numpy()[train_index], base_preds_train.numpy()[test_index]\n",
    "      print(X_tr.shape, X_te.shape, Y_tr.shape, Y_te.shape, base_preds_tr.shape, base_preds_te.shape)\n",
    "\n",
    "      # build model & run MCMC\n",
    "      bma_prior, bma_gp_config = bma_dist(X_tr, \n",
    "                                    base_preds_tr, \n",
    "                                    **bma_model_config)\n",
    "\n",
    "      bma_model_config.update(bma_gp_config)\n",
    "\n",
    "\n",
    "      bma_gp_w_samples = run_posterior_inference(model_dist=bma_prior, \n",
    "                                           model_config=bma_model_config,\n",
    "                                           Y=Y_tr, \n",
    "                                           map_config=map_config,\n",
    "                                           mcmc_config=mcmc_config)\n",
    "\n",
    "\n",
    "      bma_joint_samples = make_bma_samples(X_te, None, base_preds_te, \n",
    "                                     bma_weight_samples=bma_gp_w_samples[0],\n",
    "                                     bma_model_config=bma_model_config,\n",
    "                                     n_samples=bma_n_samples_eval, \n",
    "                                     seed=bne_seed,\n",
    "                                     y_samples_only=False)\n",
    "      y_pred = bma_joint_samples['y']\n",
    "      # compute predictive interval\n",
    "      y_pred_mean = np.mean(y_pred, axis=0)\n",
    "      y_pred_std = np.std(y_pred, axis=0)\n",
    "      y_pred_ci = np.stack([y_pred_mean - 1.96 * y_pred_std, y_pred_mean + 1.96 * y_pred_std], axis=1)\n",
    "      # compute coverage\n",
    "      coverage_bma = np.mean([(Y_te[i] > y_pred_ci[i,0]) & (Y_te[i] < y_pred_ci[i,1]) for i in range(len(Y_te))])\n",
    "      print(\"Coverage BMA: \", coverage_bma)\n",
    "\n",
    "      y_pred = tf.reduce_mean(y_pred, axis=0)\n",
    "\n",
    "      rmse_bma.append(rmse(Y_te, y_pred))\n",
    "      print(rmse_bma)\n",
    "\n",
    "print(\"RMSE LR: \", np.mean(rmse_lr), np.std(rmse_lr))\n",
    "print(\"RMSE BMA: \", np.mean(rmse_bma), np.std(rmse_bma))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 2) (6, 2) (45, 1) (6, 1) (45, 3) (6, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/keras/initializers/initializers_v2.py:121: UserWarning: The initializer OrthogonalRandomFeatures is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  f\"The initializer {self.__class__.__name__} is unseeded \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MAP:\t374008.4375...137468.59375...123397.6484375...117827.78125...114612.796875...113169.90625...112278.0703125...111652.96875...111276.6875...111043.9140625...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9959104657173157\n",
      "prior model graph: (('gp_weights', ()), ('y', ('gp_weights',)))\n",
      "Running MAP:\t6560.412109375...5773.3701171875...5770.912109375...5770.8916015625...5770.8916015625...5770.8916015625...5770.8916015625...5770.8916015625...5770.8916015625...5770.8916015625...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9996920228004456\n",
      "(250, 6, 1)\n",
      "tf.Tensor(\n",
      "[[10.870145 ]\n",
      " [10.007841 ]\n",
      " [ 6.6096005]\n",
      " [ 8.861374 ]\n",
      " [ 6.4641643]\n",
      " [ 8.8913145]], shape=(6, 1), dtype=float32) [[9.97563  ]\n",
      " [9.837391 ]\n",
      " [6.332692 ]\n",
      " [9.2525   ]\n",
      " [5.0865545]\n",
      " [8.473109 ]]\n",
      "0.7224463\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/keras/initializers/initializers_v2.py:121: UserWarning: The initializer OrthogonalRandomFeatures is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  f\"The initializer {self.__class__.__name__} is unseeded \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MAP:\t397982.75...151307.0625...138769.34375...135691.140625...134458.65625...133836.46875...133439.640625...133203.328125...131990.0...131388.6875...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9935899972915649\n",
      "prior model graph: (('gp_weights', ()), ('y', ('gp_weights',)))\n",
      "Running MAP:\t6731.94580078125...5703.3076171875...5699.2578125...5699.13330078125...5699.1337890625...5699.1337890625...5699.1337890625...5699.1337890625...5699.1337890625...5699.1337890625...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9996867775917053\n",
      "(250, 5, 1)\n",
      "tf.Tensor(\n",
      "[[10.345961]\n",
      " [ 8.802236]\n",
      " [ 8.816562]\n",
      " [ 8.664075]\n",
      " [ 7.404664]], shape=(5, 1), dtype=float32) [[9.969748]\n",
      " [8.599174]\n",
      " [8.657759]\n",
      " [9.079487]\n",
      " [6.503226]]\n",
      "0.48849705\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/keras/initializers/initializers_v2.py:121: UserWarning: The initializer OrthogonalRandomFeatures is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  f\"The initializer {self.__class__.__name__} is unseeded \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MAP:\t319771.28125...109535.203125...98943.984375...94754.75...92895.0703125...91877.546875...90036.4921875...89140.09375...88590.9453125...88189.4453125...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9966615438461304\n",
      "prior model graph: (('gp_weights', ()), ('y', ('gp_weights',)))\n",
      "Running MAP:\t6383.8671875...5688.8701171875...5686.2265625...5686.2021484375...5686.20166015625...5686.201171875...5686.201171875...5686.201171875...5686.2021484375...5686.201171875...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9996944069862366\n",
      "(250, 5, 1)\n",
      "tf.Tensor(\n",
      "[[8.593798]\n",
      " [8.83788 ]\n",
      " [8.463722]\n",
      " [8.531174]\n",
      " [7.593264]], shape=(5, 1), dtype=float32) [[ 6.3469567]\n",
      " [ 9.01     ]\n",
      " [11.023407 ]\n",
      " [ 7.4215517]\n",
      " [ 6.447826 ]]\n",
      "1.6836387\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/keras/initializers/initializers_v2.py:121: UserWarning: The initializer OrthogonalRandomFeatures is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  f\"The initializer {self.__class__.__name__} is unseeded \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MAP:\t393917.0...136974.015625...126128.828125...122682.546875...120573.9453125...119739.1640625...119316.4453125...119083.40625...118949.046875...118864.1328125...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9959431886672974\n",
      "prior model graph: (('gp_weights', ()), ('y', ('gp_weights',)))\n",
      "Running MAP:\t6999.8369140625...5876.20556640625...5871.9091796875...5871.76171875...5871.76171875...5871.76171875...5871.76171875...5871.76171875...5871.76171875...5871.76171875...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9997020363807678\n",
      "(250, 5, 1)\n",
      "tf.Tensor(\n",
      "[[9.747091 ]\n",
      " [9.137147 ]\n",
      " [7.072043 ]\n",
      " [8.583635 ]\n",
      " [6.7621365]], shape=(5, 1), dtype=float32) [[8.803155]\n",
      " [8.728161]\n",
      " [7.062264]\n",
      " [8.909402]\n",
      " [5.991228]]\n",
      "0.59309435\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/keras/initializers/initializers_v2.py:121: UserWarning: The initializer OrthogonalRandomFeatures is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  f\"The initializer {self.__class__.__name__} is unseeded \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MAP:\t391113.8125...145095.28125...132157.03125...128419.375...126845.8125...125916.109375...124941.4765625...123855.9609375...123428.2421875...123203.125...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9957589507102966\n",
      "prior model graph: (('gp_weights', ()), ('y', ('gp_weights',)))\n",
      "Running MAP:\t5710.5439453125...5007.32080078125...5004.45703125...5004.4248046875...5004.42431640625...5004.4248046875...5004.42431640625...5004.42431640625...5004.42529296875...5004.4248046875...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9997101426124573\n",
      "(250, 5, 1)\n",
      "tf.Tensor(\n",
      "[[9.016682]\n",
      " [9.043967]\n",
      " [8.765994]\n",
      " [8.39628 ]\n",
      " [9.220986]], shape=(5, 1), dtype=float32) [[ 8.640988]\n",
      " [ 8.654546]\n",
      " [ 9.376471]\n",
      " [10.250689]\n",
      " [ 8.898305]]\n",
      "0.9174344\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/keras/initializers/initializers_v2.py:121: UserWarning: The initializer OrthogonalRandomFeatures is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  f\"The initializer {self.__class__.__name__} is unseeded \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MAP:\t387665.59375...139296.46875...131194.03125...128269.5234375...122586.8828125...120386.8671875...119240.890625...118536.21875...118067.7421875...117738.8125...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9951395392417908\n",
      "prior model graph: (('gp_weights', ()), ('y', ('gp_weights',)))\n",
      "Running MAP:\t5837.6884765625...5204.3623046875...5202.0673828125...5202.04248046875...5202.04248046875...5202.04248046875...5202.0419921875...5202.04248046875...5202.0419921875...5202.04248046875...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9996982216835022\n",
      "(250, 5, 1)\n",
      "tf.Tensor(\n",
      "[[10.426801 ]\n",
      " [ 9.430908 ]\n",
      " [ 6.8458366]\n",
      " [ 7.997705 ]\n",
      " [ 7.9303446]], shape=(5, 1), dtype=float32) [[9.52807  ]\n",
      " [9.362832 ]\n",
      " [5.460345 ]\n",
      " [7.4618163]\n",
      " [6.636667 ]]\n",
      "0.9687845\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/keras/initializers/initializers_v2.py:121: UserWarning: The initializer OrthogonalRandomFeatures is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  f\"The initializer {self.__class__.__name__} is unseeded \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MAP:\t374984.21875...135668.3125...126317.203125...122510.03125...120008.8671875...117898.3359375...116895.65625...116362.6953125...115660.6640625...114873.40625...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9955177903175354\n",
      "prior model graph: (('gp_weights', ()), ('y', ('gp_weights',)))\n",
      "Running MAP:\t7292.58984375...6063.56884765625...6057.4287109375...6057.3603515625...6057.3603515625...6057.3603515625...6057.3603515625...6057.361328125...6057.361328125...6057.361328125...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9996882081031799\n",
      "(250, 5, 1)\n",
      "tf.Tensor(\n",
      "[[ 9.110606]\n",
      " [10.094742]\n",
      " [ 6.498168]\n",
      " [ 9.001045]\n",
      " [ 6.053022]], shape=(5, 1), dtype=float32) [[ 8.396441]\n",
      " [10.035838]\n",
      " [ 5.682759]\n",
      " [ 8.189075]\n",
      " [ 4.919658]]\n",
      "0.7902154\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/keras/initializers/initializers_v2.py:121: UserWarning: The initializer OrthogonalRandomFeatures is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  f\"The initializer {self.__class__.__name__} is unseeded \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MAP:\t380794.5625...144093.375...132158.5625...127967.8828125...126281.5625...125427.984375...124890.3515625...124495.53125...124172.484375...123905.1484375...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9959341883659363\n",
      "prior model graph: (('gp_weights', ()), ('y', ('gp_weights',)))\n",
      "Running MAP:\t6059.1162109375...5377.67138671875...5375.326171875...5375.29833984375...5375.298828125...5375.298828125...5375.298828125...5375.298828125...5375.298828125...5375.298828125...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9996944069862366\n",
      "(250, 5, 1)\n",
      "tf.Tensor(\n",
      "[[10.001504]\n",
      " [ 8.732644]\n",
      " [ 9.092467]\n",
      " [ 9.256559]\n",
      " [ 8.474271]], shape=(5, 1), dtype=float32) [[10.041177 ]\n",
      " [ 7.8931036]\n",
      " [ 9.7575   ]\n",
      " [ 7.8369746]\n",
      " [ 7.4827585]]\n",
      "0.91071266\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/keras/initializers/initializers_v2.py:121: UserWarning: The initializer OrthogonalRandomFeatures is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  f\"The initializer {self.__class__.__name__} is unseeded \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MAP:\t374885.28125...138506.90625...124855.7421875...120890.0546875...118846.859375...117944.0703125...117450.7734375...117162.9140625...116988.375...116823.125...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.995348334312439\n",
      "prior model graph: (('gp_weights', ()), ('y', ('gp_weights',)))\n",
      "Running MAP:\t5666.6240234375...5122.0107421875...5120.3349609375...5120.326171875...5120.326171875...5120.326171875...5120.326171875...5120.326171875...5120.326171875...5120.32666015625...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9997006058692932\n",
      "(250, 5, 1)\n",
      "tf.Tensor(\n",
      "[[8.582253]\n",
      " [9.477147]\n",
      " [8.375256]\n",
      " [9.202105]\n",
      " [8.97147 ]], shape=(5, 1), dtype=float32) [[9.035897 ]\n",
      " [9.955856 ]\n",
      " [8.191735 ]\n",
      " [7.5737705]\n",
      " [7.5904346]]\n",
      "1.0027328\n",
      "(46, 2) (5, 2) (46, 1) (5, 1) (46, 3) (5, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/keras/initializers/initializers_v2.py:121: UserWarning: The initializer OrthogonalRandomFeatures is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  f\"The initializer {self.__class__.__name__} is unseeded \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MAP:\t269462.09375...93673.859375...85569.578125...82270.5...81248.578125...80640.5546875...80200.453125...79904.1015625...79712.375...79586.3515625...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9961051940917969\n",
      "prior model graph: (('gp_weights', ()), ('y', ('gp_weights',)))\n",
      "Running MAP:\t4664.52880859375...4332.19091796875...4331.705078125...4331.705078125...4331.705078125...4331.705078125...4331.705078125...4331.70458984375...4331.70458984375...4331.70849609375...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.9997106194496155\n",
      "(250, 5, 1)\n",
      "tf.Tensor(\n",
      "[[9.590391 ]\n",
      " [9.503518 ]\n",
      " [6.494892 ]\n",
      " [5.5725927]\n",
      " [8.73055  ]], shape=(5, 1), dtype=float32) [[ 8.835652 ]\n",
      " [ 9.485    ]\n",
      " [ 1.58     ]\n",
      " [ 3.8864079]\n",
      " [10.387156 ]]\n",
      "2.4622633\n",
      "[1.6682197, 0.8446648, 2.0171714, 0.9632994, 1.7046735, 1.3922702, 2.009299, 0.8785388, 0.85990846, 3.6984842] [0.7224463, 0.48849705, 1.6836387, 0.59309435, 0.9174344, 0.9687845, 0.7902154, 0.91071266, 1.0027328, 2.4622633]\n",
      "RMSE LR:  1.603653 0.82752544\n",
      "RMSE BMA:  1.0539819 0.56039804\n"
     ]
    }
   ],
   "source": [
    "ref_model = LinearRegression()\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "rmse_lr = []\n",
    "rmse_bma = []\n",
    "rmse_gam = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train1):\n",
    "      #print(\"Train:\", train_index, \"Validation:\",test_index)\n",
    "      X_tr, X_te = X_train1[train_index], X_train1[test_index] \n",
    "      Y_tr, Y_te = Y_train[train_index], Y_train[test_index]\n",
    "      \n",
    "      # Ref: linear regression\n",
    "      ref_model.fit(X_tr, Y_tr)\n",
    "      Y_pred = ref_model.predict(X_te)\n",
    "      rmse_lr.append(rmse(Y_te, Y_pred))\n",
    "      \n",
    "\n",
    "      base_preds_tr, base_preds_te = base_preds_train.numpy()[train_index], base_preds_train.numpy()[test_index]\n",
    "      print(X_tr.shape, X_te.shape, Y_tr.shape, Y_te.shape, base_preds_tr.shape, base_preds_te.shape)\n",
    "    \n",
    "\n",
    "      # build model & run MCMC\n",
    "      bma_prior, bma_gp_config = bma_dist(X_tr, \n",
    "                                    base_preds_tr, \n",
    "                                    **bma_model_config)\n",
    "\n",
    "      bma_model_config.update(bma_gp_config)\n",
    "\n",
    "\n",
    "      bma_gp_w_samples = run_posterior_inference(model_dist=bma_prior, \n",
    "                                           model_config=bma_model_config,\n",
    "                                           Y=Y_tr, \n",
    "                                           map_config=map_config,\n",
    "                                           mcmc_config=mcmc_config)\n",
    "\n",
    "      means_tr_mcmc, X_tr_mcmc, Y_tr_mcmc = make_bma_samples(\n",
    "        X_tr, Y_tr, base_preds_tr, \n",
    "        bma_weight_samples=bma_gp_w_samples[0],\n",
    "        bma_model_config=bma_model_config,\n",
    "        n_samples=bma_n_samples_train,\n",
    "        seed=bma_seed, \n",
    "        prepare_mcmc_training=True)\n",
    "\n",
    "      means_te_mcmc = make_bma_samples(\n",
    "        X_te, None, base_preds_te, \n",
    "        bma_weight_samples=bma_gp_w_samples[0],\n",
    "        bma_model_config=bma_model_config,\n",
    "        n_samples=bma_n_samples_test,\n",
    "        seed=bma_seed)\n",
    "\n",
    "    # Construct posterior sampler.\n",
    "      bne_prior, bne_gp_config = bne_model_dist(\n",
    "          inputs=X_tr_mcmc,\n",
    "          mean_preds=means_tr_mcmc,\n",
    "          **bne_model_config)\n",
    "\n",
    "      bne_model_config.update(bne_gp_config)\n",
    "      print(f'prior model graph: {bne_prior.resolve_graph()}')\n",
    "\n",
    "      #Estimates GP weight posterior using MCMC.\n",
    "      bne_gp_w_samples = run_posterior_inference(model_dist=bne_prior,\n",
    "                                           model_config=bne_gp_config,\n",
    "                                           Y=Y_tr_mcmc,\n",
    "                                           map_config=map_config,\n",
    "                                           mcmc_config=mcmc_config,\n",
    "                                           initialize_from_map=True)\n",
    "# Generates the posterior sample for all model parameters. \n",
    "      bne_joint_samples = make_bne_samples(X_te,\n",
    "                                     mean_preds=means_te_mcmc,\n",
    "                                     bne_model_config=bne_model_config,\n",
    "                                     bne_weight_samples=bne_gp_w_samples[0],\n",
    "                                     seed=bne_seed)\n",
    "\n",
    "\n",
    "    #   bma_joint_samples = make_bma_samples(X_te, None, base_preds_te, \n",
    "    #                                  bma_weight_samples=bma_gp_w_samples[0],\n",
    "    #                                  bma_model_config=bma_model_config,\n",
    "    #                                  n_samples=bma_n_samples_eval, \n",
    "    #                                  seed=bne_seed,\n",
    "    #                                  y_samples_only=False)\n",
    "      y_pred = bne_joint_samples['y']\n",
    "      print(y_pred.shape)\n",
    "      y_pred = tf.reduce_mean(y_pred, axis=0)\n",
    "      print(y_pred, Y_te)\n",
    "      print(rmse(Y_te, y_pred))\n",
    "\n",
    "      rmse_bma.append(rmse(Y_te, y_pred))\n",
    "\n",
    "print(rmse_lr, rmse_bma)\n",
    "\n",
    "print(\"RMSE LR: \", np.mean(rmse_lr), np.std(rmse_lr))\n",
    "print(\"RMSE BMA: \", np.mean(rmse_bma), np.std(rmse_bma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[9.667572 ]\n",
      "  [9.583517 ]\n",
      "  [6.6253176]\n",
      "  [5.7201505]\n",
      "  [8.794331 ]]\n",
      "\n",
      " [[9.684673 ]\n",
      "  [9.58434  ]\n",
      "  [6.7008514]\n",
      "  [5.7876406]\n",
      "  [8.783048 ]]\n",
      "\n",
      " [[9.670104 ]\n",
      "  [9.576929 ]\n",
      "  [6.60703  ]\n",
      "  [5.7534175]\n",
      "  [8.799616 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[9.672069 ]\n",
      "  [9.577525 ]\n",
      "  [6.6116686]\n",
      "  [5.721097 ]\n",
      "  [8.799673 ]]\n",
      "\n",
      " [[9.685108 ]\n",
      "  [9.582404 ]\n",
      "  [6.6198134]\n",
      "  [5.7160015]\n",
      "  [8.782711 ]]\n",
      "\n",
      " [[9.686399 ]\n",
      "  [9.5675125]\n",
      "  [6.6691146]\n",
      "  [5.780143 ]\n",
      "  [8.7887   ]]], shape=(250, 5, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(means_te_mcmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check 10-fold Spatial Cross Validation RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold_id=10\n",
    "# X_te = X_train1[training51.index[training51[\"fold\"] == fold_id]]\n",
    "# X_tr = X_train1[training51.index[training51[\"fold\"] != fold_id]]\n",
    "# Y_te = Y_train[training51.index[training51[\"fold\"] == fold_id]]\n",
    "# Y_tr = Y_train[training51.index[training51[\"fold\"] != fold_id]]\n",
    "\n",
    "# base_preds_tr=base_preds_train.numpy()[training51.index[training51[\"fold\"] != fold_id]]\n",
    "# base_preds_te=base_preds_train.numpy()[training51.index[training51[\"fold\"] == fold_id]]\n",
    "\n",
    "# # build model & run MCMC\n",
    "# bma_prior, bma_gp_config = bma_dist(X_tr, \n",
    "#                                     base_preds_tr, \n",
    "#                                     **bma_model_config)\n",
    "\n",
    "# bma_model_config.update(bma_gp_config)\n",
    "\n",
    "\n",
    "# bma_gp_w_samples = run_posterior_inference(model_dist=bma_prior, \n",
    "#                                            model_config=bma_model_config,\n",
    "#                                            Y=Y_tr, \n",
    "#                                            map_config=map_config,\n",
    "#                                            mcmc_config=mcmc_config)\n",
    "\n",
    "\n",
    "# bma_joint_samples = make_bma_samples(X_te, None, base_preds_te, \n",
    "#                                      bma_weight_samples=bma_gp_w_samples[0],\n",
    "#                                      bma_model_config=bma_model_config,\n",
    "#                                      n_samples=bma_n_samples_eval, \n",
    "#                                      seed=bne_seed,\n",
    "#                                      y_samples_only=False)\n",
    "# y_pred = bma_joint_samples['y']\n",
    "# y_pred = tf.reduce_mean(y_pred, axis=0)\n",
    "\n",
    "# print(rmse(Y_te, y_pred))\n",
    "\n",
    "# # Construct data from BMA samples, shapes (num_samples * num_data, ...)\n",
    "# means_tr_mcmc, X_tr_mcmc, Y_tr_mcmc = make_bma_samples(\n",
    "#     X_tr, Y_tr, base_preds_tr, \n",
    "#     bma_weight_samples=bma_gp_w_samples[0],\n",
    "#     bma_model_config=bma_model_config,\n",
    "#     n_samples=bma_n_samples_train,\n",
    "#     seed=bma_seed, \n",
    "#     prepare_mcmc_training=True)\n",
    "\n",
    "# # Mean samples based on test data, shape (num_samples, num_data, num_output).\n",
    "# # It is used to generate final examples in `make_bne_samples()`.\n",
    "# means_te_mcmc = make_bma_samples(\n",
    "#     X_te, None, base_preds_te, \n",
    "#     bma_weight_samples=bma_gp_w_samples[0],\n",
    "#     bma_model_config=bma_model_config,\n",
    "#     n_samples=bma_n_samples_test,\n",
    "#     seed=bma_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# rmse_bma = []\n",
    "# rmse_bne = []\n",
    "\n",
    "# for fold_id in range(1, 11):\n",
    "#     # prepare cross-validation data\n",
    "#     X_te = X_train1[training51.index[training51[\"fold\"] == fold_id]]\n",
    "#     X_tr = X_train1[training51.index[training51[\"fold\"] != fold_id]]\n",
    "#     Y_te = Y_train[training51.index[training51[\"fold\"] == fold_id]]\n",
    "#     Y_tr = Y_train[training51.index[training51[\"fold\"] != fold_id]]\n",
    "\n",
    "#     base_preds_tr=base_preds_train.numpy()[training51.index[training51[\"fold\"] != fold_id]]\n",
    "#     base_preds_te=base_preds_train.numpy()[training51.index[training51[\"fold\"] == fold_id]]\n",
    "\n",
    "#     # build model & run MCMC\n",
    "#     bma_prior, bma_gp_config = bma_dist(X_tr, \n",
    "#                                     base_preds_tr, \n",
    "#                                     **bma_model_config)\n",
    "\n",
    "#     bma_model_config.update(bma_gp_config)\n",
    "\n",
    "#     print(\"BMA model config: \", bma_model_config, \"mcmc_config: \", mcmc_config, \"map_config: \", map_config)\n",
    "#     bma_gp_w_samples = run_posterior_inference(model_dist=bma_prior, \n",
    "#                                            model_config=bma_model_config,\n",
    "#                                            Y=Y_tr, \n",
    "#                                            map_config=map_config,\n",
    "#                                            mcmc_config=mcmc_config)\n",
    "\n",
    "\n",
    "#     bma_joint_samples = make_bma_samples(X_te, None, base_preds_te, \n",
    "#                                      bma_weight_samples=bma_gp_w_samples[0],\n",
    "#                                      bma_model_config=bma_model_config,\n",
    "#                                      n_samples=bma_n_samples_eval, \n",
    "#                                      seed=bne_seed,\n",
    "#                                      y_samples_only=False)\n",
    "\n",
    "#     y_pred = bma_joint_samples['y']\n",
    "#     y_pred = tf.reduce_mean(y_pred, axis=0)\n",
    "#     rmse_bma.append(rmse(Y_te, y_pred))\n",
    "#     print(rmse_bma)\n",
    "\n",
    "#     # Construct data from BMA samples, shapes (num_samples * num_data, ...)\n",
    "#     means_tr_mcmc, X_tr_mcmc, Y_tr_mcmc = make_bma_samples(\n",
    "#         X_tr, Y_tr, base_preds_tr, \n",
    "#         bma_weight_samples=bma_gp_w_samples[0],\n",
    "#         bma_model_config=bma_model_config,\n",
    "#         n_samples=bma_n_samples_train,\n",
    "#         seed=bma_seed, \n",
    "#         prepare_mcmc_training=True)\n",
    "\n",
    "#     # Mean samples based on test data, shape (num_samples, num_data, num_output).\n",
    "#     # It is used to generate final examples in `make_bne_samples()`.\n",
    "#     means_te_mcmc = make_bma_samples(\n",
    "#         X_te, None, base_preds_te, \n",
    "#         bma_weight_samples=bma_gp_w_samples[0],\n",
    "#         bma_model_config=bma_model_config,\n",
    "#         n_samples=bma_n_samples_test,\n",
    "#         seed=bma_seed)\n",
    "\n",
    "#     # # # BNE GP Configs.\n",
    "# # # lengthscale = 1. # @param\n",
    "# # # l2_regularizer = 10. # @param\n",
    "\n",
    "# # BNE model configs. \n",
    "# # If estimate_mean=False, only estimates a constant variance on top of the \n",
    "# # original model.\n",
    "#     estimate_mean = \"True\" # @param [\"True\", \"False\"]\n",
    "#     variance_prior_mean=0. # @param\n",
    "# # # MAP and MCMC configs\n",
    "# # map_step_size=0.1 # @param\n",
    "# # map_num_steps=10_000 # @param\n",
    "\n",
    "# # mcmc_step_size=1e-2 # @param\n",
    "# # mcmc_num_steps=10_000 # @param\n",
    "\n",
    "#     bne_gp_config = DEFAULT_GP_CONFIG.copy()\n",
    "#     bne_model_config = DEFAULT_BNE_CONFIG.copy()\n",
    "\n",
    "#     map_config = DEFAULT_MAP_CONFIG.copy()\n",
    "#     mcmc_config = DEFAULT_MCMC_CONFIG.copy()\n",
    "\n",
    "\n",
    "#     bne_gp_config.update(dict(lengthscale=bne_gp_lengthscale, \n",
    "#                           l2_regularizer=bne_gp_l2_regularizer))\n",
    "#     bne_model_config.update(dict(estimate_mean=eval(estimate_mean),\n",
    "#                              variance_prior_mean=variance_prior_mean,\n",
    "#                              **bne_gp_config))\n",
    "\n",
    "#     map_config.update(dict(learning_rate=map_step_size,\n",
    "#                        num_steps=map_num_steps))\n",
    "#     mcmc_config.update(dict(step_size=mcmc_step_size, \n",
    "#                         num_steps=mcmc_num_steps,\n",
    "#                        burnin=mcmc_burnin,\n",
    "#                        nchain=mcmc_nchain))\n",
    "    \n",
    "#     # build model & run MCMC\n",
    "#     bne_prior, bne_gp_config = bne_model_dist(\n",
    "#             inputs=X_tr_mcmc,\n",
    "#             mean_preds=means_tr_mcmc,\n",
    "#             **bne_model_config)\n",
    "\n",
    "#     bne_model_config.update(bne_gp_config)\n",
    "\n",
    "#     print(\"BNE model config: \", bne_model_config, \"mcmc_config: \", mcmc_config, \"map_config: \", map_config)\n",
    "#     # Estimates GP weight posterior using MCMC.\n",
    "#     bne_gp_w_samples = run_posterior_inference(model_dist=bne_prior,\n",
    "#                                             model_config=bne_gp_config,\n",
    "#                                             Y=Y_tr_mcmc,\n",
    "#                                             map_config=map_config,\n",
    "#                                             mcmc_config=mcmc_config,\n",
    "#                                             initialize_from_map=True)\n",
    "#     # Generates the posterior sample for all model parameters. \n",
    "#     bne_joint_samples = make_bne_samples(X_te,\n",
    "#                                         mean_preds=means_te_mcmc,\n",
    "#                                         bne_model_config=bne_model_config,\n",
    "#                                         bne_weight_samples=bne_gp_w_samples[0],\n",
    "#                                         seed=bne_seed)\n",
    "    \n",
    "#     y_pred = bne_joint_samples['y']\n",
    "#     means_pred = np.mean(y_pred, axis=0)\n",
    "#     rmse_bne.append(rmse(Y_te, y_pred))\n",
    "#     print(rmse_bne)\n",
    "\n",
    "    \n",
    "# print(rmse_bma, rmse_bne)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('gp_weights', ()), ('y', ('gp_weights',)))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bma_prior, bma_gp_config = bma_dist(X_train1, \n",
    "                                    base_preds_train, \n",
    "                                    **bma_model_config)\n",
    "\n",
    "bma_model_config.update(bma_gp_config)\n",
    "\n",
    "# Check if the model graph is specified correctly.\n",
    "bma_prior.resolve_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lengthscale': 0.07,\n",
       " 'l2_regularizer': 0.15,\n",
       " 'hidden_units': 1024,\n",
       " 'y_noise_std': 0.01,\n",
       " 'activation': None,\n",
       " 'units': 3,\n",
       " 'seed': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(bma_model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MAP:\t409032.25...157770.984375...141512.0625...131225.21875...126107.3125...123341.8359375...121954.1328125...121116.6796875...120512.6015625...120008.921875...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.6501743197441101\n"
     ]
    }
   ],
   "source": [
    "# bma_gp_w_samples, chain_samples, sampler_stat = run_posterior_inference(model_dist=bma_prior, \n",
    "#                                            model_config=bma_model_config,\n",
    "#                                            Y=Y_train, \n",
    "#                                            map_config=map_config,\n",
    "#                                            mcmc_config=mcmc_config)\n",
    "\n",
    "# Above the debug mode\n",
    "\n",
    "bma_gp_w_samples = run_posterior_inference(model_dist=bma_prior, \n",
    "                                           model_config=bma_model_config,\n",
    "                                           Y=Y_train, \n",
    "                                           map_config=map_config,\n",
    "                                           mcmc_config=mcmc_config)\n",
    "\n",
    "\n",
    "bma_joint_samples = make_bma_samples(X_test1, None, base_preds_test, \n",
    "                                     bma_weight_samples=bma_gp_w_samples[0],\n",
    "                                     bma_model_config=bma_model_config,\n",
    "                                     n_samples=bma_n_samples_eval, \n",
    "                                     seed=bne_seed,\n",
    "                                     y_samples_only=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(chain_samples[:, 9, 31, 1], c='b', alpha=.3)\n",
    "# # plt.title('Traceplot')\n",
    "# # plt.plot(bma_gp_w_samples[1][:,9, 127, 1].numpy(), 'b')\n",
    "# # plt.xlabel('Iteration')\n",
    "# # plt.ylabel('Position')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data for BAE/BNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct data from BMA samples, shapes (num_samples * num_data, ...)\n",
    "means_train_mcmc, X_train_mcmc, Y_train_mcmc = make_bma_samples(\n",
    "    X_train1, Y_train, base_preds_train, \n",
    "    bma_weight_samples=bma_gp_w_samples[0],\n",
    "    bma_model_config=bma_model_config,\n",
    "    n_samples=bma_n_samples_train,\n",
    "    seed=bma_seed, \n",
    "    prepare_mcmc_training=True)\n",
    "\n",
    "# Mean samples based on test data, shape (num_samples, num_data, num_output).\n",
    "# It is used to generate final examples in `make_bne_samples()`.\n",
    "means_test_mcmc = make_bma_samples(\n",
    "    X_test1, None, base_preds_test, \n",
    "    bma_weight_samples=bma_gp_w_samples[0],\n",
    "    bma_model_config=bma_model_config,\n",
    "    n_samples=bma_n_samples_test,\n",
    "    seed=bma_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Additive Ensemble\n",
    "\n",
    "Given $\\mu(x)$ the posterior of a Bayesian ensemble model, the Bayesian Additive Ensemble is defined as:    \n",
    "\n",
    "$y \\sim N(\\mu(x) + r(x), \\sigma^2)$\n",
    "\n",
    "$r \\sim GaussianProcess(0, k)$\n",
    "\n",
    "The additive ensemble $r(x)$ services two purposes: \n",
    "\n",
    "1. Mitigates systematic bias in model prediction; \n",
    "2. Quantifies the model's epistemic uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # BNE GP Configs.\n",
    "# # lengthscale = 1. # @param\n",
    "# # l2_regularizer = 10. # @param\n",
    "\n",
    "# BNE model configs. \n",
    "# If estimate_mean=False, only estimates a constant variance on top of the \n",
    "# original model.\n",
    "estimate_mean = \"True\" # @param [\"True\", \"False\"]\n",
    "variance_prior_mean=0. # @param\n",
    "# # MAP and MCMC configs\n",
    "# map_step_size=0.1 # @param\n",
    "# map_num_steps=10_000 # @param\n",
    "\n",
    "# mcmc_step_size=1e-2 # @param\n",
    "# mcmc_num_steps=10_000 # @param\n",
    "\n",
    "bne_gp_config = DEFAULT_GP_CONFIG.copy()\n",
    "bne_model_config = DEFAULT_BNE_CONFIG.copy()\n",
    "\n",
    "map_config = DEFAULT_MAP_CONFIG.copy()\n",
    "mcmc_config = DEFAULT_MCMC_CONFIG.copy()\n",
    "\n",
    "\n",
    "bne_gp_config.update(dict(lengthscale=bne_gp_lengthscale, \n",
    "                          l2_regularizer=bne_gp_l2_regularizer))\n",
    "bne_model_config.update(dict(estimate_mean=eval(estimate_mean),\n",
    "                             variance_prior_mean=variance_prior_mean,\n",
    "                             **bne_gp_config))\n",
    "\n",
    "map_config.update(dict(learning_rate=map_step_size,\n",
    "                       num_steps=map_num_steps))\n",
    "mcmc_config.update(dict(step_size=mcmc_step_size, \n",
    "                        num_steps=mcmc_num_steps,\n",
    "                       burnin=mcmc_burnin,\n",
    "                       nchain=mcmc_nchain,\n",
    "                       debug_mode=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior model graph: (('gp_weights', ()), ('y', ('gp_weights',)))\n"
     ]
    }
   ],
   "source": [
    "# Construct posterior sampler.\n",
    "bne_prior, bne_gp_config = bne_model_dist(\n",
    "    inputs=X_train_mcmc,\n",
    "    mean_preds=means_train_mcmc,\n",
    "    **bne_model_config)\n",
    "\n",
    "bne_model_config.update(bne_gp_config)\n",
    "print(f'prior model graph: {bne_prior.resolve_graph()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MAP:\t18988.62890625...15931.923828125...15861.28515625...15824.08984375...15795.41015625...15773.033203125...15754.7421875...15737.87890625...15720.84375...15703.337890625...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.8144306540489197\n"
     ]
    }
   ],
   "source": [
    "# Estimates GP weight posterior using MCMC.\n",
    "bne_gp_w_samples = run_posterior_inference(model_dist=bne_prior,\n",
    "                                           model_config=bne_gp_config,\n",
    "                                           Y=Y_train_mcmc,\n",
    "                                           map_config=map_config,\n",
    "                                           mcmc_config=mcmc_config,\n",
    "                                           initialize_from_map=True)\n",
    "# Generates the posterior sample for all model parameters. \n",
    "bne_joint_samples = make_bne_samples(X_test1,\n",
    "                                     mean_preds=means_test_mcmc,\n",
    "                                     bne_model_config=bne_model_config,\n",
    "                                     bne_weight_samples=bne_gp_w_samples[0],\n",
    "                                     seed=bne_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_pred_bae = {k: np.mean(np.nan_to_num(bne_joint_samples[k]), axis=0) for k in ('y', 'mean_original', 'resid')}\n",
    "surface_var_bae = {k: np.var(np.nan_to_num(bne_joint_samples[k]), axis=0) for k in ('y', 'mean_original', 'resid')}\n",
    "\n",
    "# # dealing with NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Nonparametric Ensemble (Variance Only)\n",
    "So far, we are only estimating the mean-component of the model, i.e., we are assuming: \n",
    "\n",
    "$y \\sim Gaussian(m(x), \\sigma^2); \\quad m(x) = GP(0, k)$.\n",
    "\n",
    "By doing so, the model is implicitly assuming the distribution of $y$ is always a symmetric Gaussian distribution with constant mean across space and time. As a result, our model can only quantify model uncertainty (due to lack of data) via the GP prior, but cannot flexibly capture the data uncertainty that is inherent to the empirical distribution of y.\n",
    "\n",
    "To resolve this, we extend the ensemble's outcome distribution $y | f$ by also estimating the higher moments of the data distribution (e.g., variance, skewness, etc) using flexible estimators. Specifically, we specify the outcome distribution family to the [maximum-entropy distribution](https://en.wikipedia.org/wiki/Principle_of_maximum_entropy) given the known moments, so the predictive distribution is [minimax](https://arxiv.org/pdf/math/0410076.pdf) and still statistically efficient to estimate.\n",
    "\n",
    "For example, when we want to estimate the first two moments (mean and variance) of the distribution, this leads to a Gaussian distribution with spatio-temporally adaptive variance $\\sigma(x)^2$:\n",
    "\n",
    "$$y \\sim Gaussian(m(x), \\sigma(x)^2); \\quad \\mbox{where} \\quad m \\sim GP(0, k_m), \\sigma \\sim GP(0, k_\\sigma)$$\n",
    "\n",
    "and when we want to estimate the first three moments (mean and variance) of the distribution, this leads to a [Exponentially-modifed Gaussian](https://en.wikipedia.org/wiki/Exponentially_modified_Gaussian_distribution) (EMG) distribution with spatio-temporally adaptive variance $\\sigma(x)^2$ and skewness $\\lambda(x)$:\n",
    "\n",
    "$$y \\sim EMG(m(x), \\sigma(x)^2, \\lambda(x)); \\quad \\mbox{where} \\quad m \\sim GP(0, k_m), \\sigma \\sim GP(0, k_\\sigma), \\lambda \\sim GP(0, k_\\lambda)$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model & Run MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior model graph: (('gp_weights', ()), ('y', ('gp_weights',)))\n",
      "Running MAP:\t18560.0390625...16146.0869140625...15960.45703125...15895.189453125...15861.62890625...15838.482421875...15818.033203125...15799.189453125...15781.728515625...15765.9228515625...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.8152660131454468\n"
     ]
    }
   ],
   "source": [
    "# Construct posterior sampler.\n",
    "bne_prior, bne_gp_config = bne_model_dist(\n",
    "    inputs=X_train_mcmc,\n",
    "    mean_preds=means_train_mcmc,\n",
    "    **bne_model_config)\n",
    "\n",
    "bne_model_config.update(bne_gp_config)\n",
    "print(f'prior model graph: {bne_prior.resolve_graph()}')\n",
    "\n",
    "# Estimates GP weight posterior using MCMC.\n",
    "bne_gp_w_samples = run_posterior_inference(model_dist=bne_prior,\n",
    "                                           model_config=bne_gp_config,\n",
    "                                           Y=Y_train_mcmc,\n",
    "                                           map_config=map_config,\n",
    "                                           mcmc_config=mcmc_config,\n",
    "                                           initialize_from_map=True)\n",
    "# Generates the posterior sample for all model parameters. \n",
    "bne_joint_samples = make_bne_samples(X_test1,\n",
    "                                     mean_preds=means_test_mcmc,\n",
    "                                     bne_model_config=bne_model_config,\n",
    "                                     bne_weight_samples=bne_gp_w_samples[0],\n",
    "                                     seed=bne_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_pred_bne_vo = {k: np.mean(np.nan_to_num(bne_joint_samples[k]), axis=0) for k in ('y', 'mean_original', 'resid')}\n",
    "surface_var_bne_vo = {k: np.var(np.nan_to_num(bne_joint_samples[k]), axis=0) for k in ('y', 'mean_original', 'resid')}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88_VOXlgq9n_"
   },
   "source": [
    "## Bayesian Nonparametric Ensemble (Variance + Skewness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model & Run MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior model graph: (('gp_weights', ()), ('y', ('gp_weights',)))\n",
      "Running MAP:\t18727.0078125...16512.93359375...16453.0...16425.234375...16398.06640625...16369.251953125...16338.7685546875...16307.216796875...16276.2314453125...16247.6259765625...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.7172572612762451\n"
     ]
    }
   ],
   "source": [
    "# Construct prior distribution.\n",
    "bne_prior, bne_gp_config = bne_model_dist(\n",
    "    inputs=X_train_mcmc,\n",
    "    mean_preds=means_train_mcmc,\n",
    "    **bne_model_config)\n",
    "\n",
    "bne_model_config.update(bne_gp_config)\n",
    "print(f'prior model graph: {bne_prior.resolve_graph()}')\n",
    "# Estimates GP weight posterior using MCMC.\n",
    "bne_gp_w_samples = run_posterior_inference(model_dist=bne_prior,\n",
    "                                           model_config=bne_gp_config,\n",
    "                                           Y=Y_train_mcmc,\n",
    "                                           map_config=map_config,\n",
    "                                           mcmc_config=mcmc_config,\n",
    "                                           initialize_from_map=True)\n",
    "# Generates the posterior sample for all model parameters. \n",
    "bne_joint_samples = make_bne_samples(X_test1,\n",
    "                                     mean_preds=means_test_mcmc,\n",
    "                                     bne_model_config=bne_model_config,\n",
    "                                     bne_weight_samples=bne_gp_w_samples[0],\n",
    "                                     seed=bne_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_pred_bne_vs = {k: np.mean(np.nan_to_num(bne_joint_samples[k]), axis=0) for k in ('y', 'mean_original', 'resid')}\n",
    "surface_var_bne_vs = {k: np.var(np.nan_to_num(bne_joint_samples[k]), axis=0) for k in ('y', 'mean_original', 'resid')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_DATA_ADDR_PREFIX = \"./example/data\"\n",
    "# Tuning Parameters\n",
    "BMA_lenthscale = bma_gp_lengthscale\n",
    "#BNE_lenthscale = bne_gp_lengthscale\n",
    "BMA_L2 = bma_gp_l2_regularizer\n",
    "#BNE_L2 = bne_gp_l2_regularizer\n",
    "_SAVE_ADDR_PREFIX = \"./pic_1028/BMA_lenthscale_{}_L2_{}\".format(BMA_lenthscale, BMA_L2)\n",
    "\n",
    "path=_SAVE_ADDR_PREFIX\n",
    "isExists=os.path.exists(path) #true\n",
    "\n",
    "if not isExists:\n",
    "    os.makedirs(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The predictive surface of individual base models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate = np.asarray(base_model_predictions_eastMA[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "monitors = np.asarray(training_eastMA_noMI[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "base_model_names = [\"pred_av\", \"pred_gs\", \"pred_caces\"]\n",
    "\n",
    "base_model_predictions_eastMA[[\"pred_av\", \"pred_gs\", \"pred_caces\"]] = np.where(np.isnan(base_model_predictions_eastMA[[\"pred_av\", \"pred_gs\", \"pred_caces\"]]), 0, base_model_predictions_eastMA[[\"pred_av\", \"pred_gs\", \"pred_caces\"]])\n",
    "color_norm_base = make_color_norm(\n",
    "    base_model_predictions_eastMA[[\"pred_av\", \"pred_gs\", \"pred_caces\"]],   \n",
    "    method=\"percentile\")\n",
    "\n",
    "for base_model_name in base_model_names:\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                             'base_model_{}_bmals_{}_r_{}.png'.format(\n",
    "                                 base_model_name, bma_gp_lengthscale,  bma_gp_l2_regularizer))\n",
    "    \n",
    "    posterior_heatmap_2d(base_model_predictions_eastMA[base_model_name], coordinate,\n",
    "                         monitors,\n",
    "                         cmap='RdYlGn_r',\n",
    "                         norm=color_norm_base, \n",
    "                         #norm_method=\"percentile\",\n",
    "                         save_addr=save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The predictive surface of individual BNE gp weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "bma_ensemble_weights = bma_joint_samples['ensemble_weights']\n",
    "ensemble_weights_val = tf.reduce_mean(bma_ensemble_weights, axis=0)\n",
    "\n",
    "weights_dict = {\n",
    "    \"AV\": ensemble_weights_val[:, 0],\n",
    "    \"GS\": ensemble_weights_val[:,1],\n",
    "    \"CACES\": ensemble_weights_val[:,2],\n",
    "}\n",
    "#weights_dict\n",
    "color_norm_weights = make_color_norm(\n",
    "    list(weights_dict.values()),#[2],   \n",
    "    method=\"percentile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_weights_var = np.var(bma_ensemble_weights, axis=0)\n",
    "weights_var_dict = {\n",
    "    \"AV\": ensemble_weights_var[:, 0],\n",
    "    \"GS\": ensemble_weights_var[:,1],\n",
    "    \"CACES\": ensemble_weights_var[:,2],\n",
    "}\n",
    "#weights_dict\n",
    "color_norm_weights_var = make_color_norm(\n",
    "    list(weights_var_dict.values()),#[0],   \n",
    "    method=\"percentile\")\n",
    "# display(ensemble_weights_val,ensemble_weights_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_names = [\"AV\", \"GS\", \"CACES\"]\n",
    "for base_model_name in base_model_names:\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                             'base_weights_{}_bmals_{}_r_{}.png'.format(\n",
    "                                 base_model_name, bma_gp_lengthscale,  bma_gp_l2_regularizer))\n",
    "    \n",
    "    posterior_heatmap_2d(weights_dict[base_model_name], coordinate,\n",
    "                         monitors,\n",
    "                         cmap='viridis',\n",
    "                         norm=color_norm_weights, \n",
    "                         #norm_method=\"percentile\",\n",
    "                         #save_addr='')\n",
    "                         save_addr=save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot weights' variance\n",
    "for base_model_name in base_model_names:\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                             'base_wvar_{}_bmals_{}_r_{}.png'.format(\n",
    "                                 base_model_name, bma_gp_lengthscale,  bma_gp_l2_regularizer))\n",
    "    \n",
    "    posterior_heatmap_2d(weights_var_dict[base_model_name], coordinate,\n",
    "                         monitors,\n",
    "                         cmap='viridis',\n",
    "                         norm=color_norm_weights_var, \n",
    "                         #norm_method=\"percentile\",\n",
    "                         #save_addr='')\n",
    "                         save_addr=save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. The predictive surface of Y_mean, residual process, and Y_mean + residual process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BAE\n",
    "color_norm_pred = make_color_norm(\n",
    "    #np.nan_to_num(list(surface_pred_bae.values())[:2][0]),\n",
    "    list(surface_pred_bae.values())[:2],  \n",
    "    method=\"percentile\")\n",
    "\n",
    "color_norm_pred_r = make_color_norm(\n",
    "    #np.nan_to_num(list(surface_pred_bae.values())[2:]),\n",
    "    list(surface_pred_bae.values())[2],  \n",
    "    method=\"residual_percentile\")\n",
    "\n",
    "\n",
    "for name, value in surface_pred_bae.items():\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                            'BAE_{}_bma:ls_{}_r_{}_bne:ls_{}_r_{}.png'.format(\n",
    "                                name, bma_gp_lengthscale,  bma_gp_l2_regularizer,\n",
    "                                bne_gp_lengthscale, bne_gp_l2_regularizer))\n",
    "\n",
    "    value = np.where(np.isnan(value), 0, value)\n",
    "    color_norm = posterior_heatmap_2d(value, X=coordinate, X_monitor=monitors,\n",
    "                                                  cmap='RdYlGn_r',\n",
    "                    norm= color_norm_pred_r if name=='resid' else color_norm_pred,\n",
    "                    #norm_method=\"percentile\",\n",
    "                    #save_addr='')\n",
    "                    save_addr=save_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BNE vo\n",
    "color_norm_pred = make_color_norm(\n",
    "    #np.nan_to_num(list(surface_pred_bae.values())[:2][0]),\n",
    "    list(surface_pred_bne_vo.values())[:2],  \n",
    "    method=\"percentile\")\n",
    "\n",
    "color_norm_pred_r = make_color_norm(\n",
    "    #np.nan_to_num(list(surface_pred_bae.values())[2:]),\n",
    "    list(surface_pred_bne_vo.values())[2],  \n",
    "    method=\"residual_percentile\")\n",
    "\n",
    "\n",
    "for name, value in surface_pred_bne_vo.items():\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                            'BNEvo_{}_bma:ls_{}_r_{}_bne:ls_{}_r_{}.png'.format(\n",
    "                                name, bma_gp_lengthscale,  bma_gp_l2_regularizer,\n",
    "                                bne_gp_lengthscale, bne_gp_l2_regularizer))\n",
    "\n",
    "    value = np.where(np.isnan(value), 0, value)\n",
    "    color_norm = posterior_heatmap_2d(value, X=coordinate, X_monitor=monitors,\n",
    "                                                  cmap='RdYlGn_r',\n",
    "                    norm= color_norm_pred_r if name=='resid' else color_norm_pred,\n",
    "                                      save_addr=save_name)\n",
    "                    #norm_method=\"percentile\",\n",
    "                    #save_addr='')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BNE v+s\n",
    "color_norm_pred = make_color_norm(\n",
    "    #np.nan_to_num(list(surface_pred_bae.values())[:2][0]),\n",
    "    list(surface_pred_bne_vs.values())[:2],  \n",
    "    method=\"percentile\")\n",
    "\n",
    "color_norm_pred_r = make_color_norm(\n",
    "    #np.nan_to_num(list(surface_pred_bae.values())[2:]),\n",
    "    list(surface_pred_bne_vs.values())[2],  \n",
    "    method=\"residual_percentile\")\n",
    "\n",
    "\n",
    "for name, value in surface_pred_bne_vs.items():\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                            'BNEvs_{}_bma:ls_{}_r_{}_bne:ls_{}_r_{}.png'.format(name, bma_gp_lengthscale, \n",
    "                                bma_gp_l2_regularizer, bne_gp_lengthscale, bne_gp_l2_regularizer))\n",
    "\n",
    "    value = np.where(np.isnan(value), 0, value)\n",
    "    color_norm = posterior_heatmap_2d(value, X=coordinate, X_monitor=monitors,\n",
    "                                                  cmap='RdYlGn_r',\n",
    "                    norm= color_norm_pred_r if name=='resid' else color_norm_pred,\n",
    "                    #norm_method=\"percentile\",\n",
    "                    #save_addr='')\n",
    "                save_addr=save_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.The predictive variance of Y_mean, residual process, and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAE\n",
    "color_norm_var = make_color_norm(\n",
    "    list(surface_var_bae.values())[:2], \n",
    "    method=\"percentile\")\n",
    "\n",
    "color_norm_var_r = make_color_norm(\n",
    "    list(surface_var_bae.values())[2], \n",
    "    method=\"percentile\")\n",
    "\n",
    "\n",
    "for name, value in surface_var_bae.items():\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                            'var_BAE_{}_bma:ls_{}_r_{}_bne:ls_{}_r_{}.png'.format(\n",
    "                                name, bma_gp_lengthscale,  bma_gp_l2_regularizer,\n",
    "                                bne_gp_lengthscale, bne_gp_l2_regularizer))\n",
    "    #value = np.where(np.isnan(value), 0, value)\n",
    "    color_norm = posterior_heatmap_2d(value, X=coordinate, X_monitor=monitors,\n",
    "                                cmap='inferno_r',\n",
    "                                norm= color_norm_var_r if name=='resid' else color_norm_var,\n",
    "                                #norm_method=\"percentile\",\n",
    "                                save_addr=save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BNE vo\n",
    "color_norm_var = make_color_norm(\n",
    "    list(surface_var_bne_vo.values())[:2], \n",
    "    method=\"percentile\")\n",
    "\n",
    "color_norm_var_r = make_color_norm(\n",
    "    list(surface_var_bne_vo.values())[2], \n",
    "    method=\"percentile\")\n",
    "\n",
    "\n",
    "for name, value in surface_var_bne_vo.items():\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                            'var_BNEvo_{}_bma:ls_{}_r_{}_bne:ls_{}_r_{}.png'.format(\n",
    "                                name, bma_gp_lengthscale,  bma_gp_l2_regularizer,\n",
    "                                bne_gp_lengthscale, bne_gp_l2_regularizer))\n",
    "    #value = np.where(np.isnan(value), 0, value)\n",
    "    color_norm = posterior_heatmap_2d(value, X=coordinate, X_monitor=monitors,\n",
    "                                cmap='inferno_r',\n",
    "                                norm= color_norm_var_r if name=='resid' else color_norm_var,\n",
    "                                #norm_method=\"percentile\",\n",
    "                                save_addr=save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BNE v+s\n",
    "color_norm_var = make_color_norm(\n",
    "    list(surface_var_bne_vs.values())[:2], \n",
    "    method=\"percentile\")\n",
    "\n",
    "color_norm_var_r = make_color_norm(\n",
    "    list(surface_var_bne_vs.values())[2], \n",
    "    method=\"percentile\")\n",
    "\n",
    "\n",
    "for name, value in surface_var_bne_vs.items():\n",
    "    save_name = os.path.join(_SAVE_ADDR_PREFIX,\n",
    "                            'var_BNEvs_{}_bma:ls_{}_r_{}_bne:ls_{}_r_{}.png'.format(\n",
    "                                name, bma_gp_lengthscale,  bma_gp_l2_regularizer,\n",
    "                                bne_gp_lengthscale, bne_gp_l2_regularizer))\n",
    "    #value = np.where(np.isnan(value), 0, value)\n",
    "    color_norm = posterior_heatmap_2d(value, X=coordinate, X_monitor=monitors,\n",
    "                                cmap='inferno_r',\n",
    "                                norm= color_norm_var_r if name=='resid' else color_norm_var,\n",
    "                                #norm_method=\"percentile\",\n",
    "                                save_addr=save_name)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "FyVOAW4EODnT",
    "ebzyBOEoNQ_a",
    "vAgjEq1-dty-"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fcc6cf470fa43d25f7728c2f3c746fc9b5580c34ff527761ed8536047e15184c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
